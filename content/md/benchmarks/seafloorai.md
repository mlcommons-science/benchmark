# SeafloorAI

<p><a class="md-button back-link" href="../">‚Üê Back to all benchmarks</a></p>
<div class="info-block meta-block">
  <p class="meta-row"><span class="meta-label">Date</span><span class="meta-sep">:</span> <span class="meta-value">2024-12-13</span></p>
  <p class="meta-row"><span class="meta-label">Name</span><span class="meta-sep">:</span> <span class="meta-value">SeafloorAI</span></p>
  <p class="meta-row"><span class="meta-label">Domain</span><span class="meta-sep">:</span> <span class="meta-value">Marine Science; Vision-Language</span></p>
  <p class="meta-row"><span class="meta-label">Focus</span><span class="meta-sep">:</span> <span class="meta-value">Large-scale vision-language dataset for seafloor mapping and geological classification</span></p>
  <p class="meta-row"><span class="meta-label">Task Types</span><span class="meta-sep">:</span> <span class="meta-value">Image segmentation, Vision-language QA</span></p>
  <p class="meta-row"><span class="meta-label">Metrics</span><span class="meta-sep">:</span> <span class="meta-value">Segmentation pixel accuracy, QA accuracy</span></p>
  <p class="meta-row"><span class="meta-label">Models</span><span class="meta-sep">:</span> <span class="meta-value">SegFormer, ViLT-style multimodal models</span></p>
</div>
<h3>Keywords</h3>

<div class="chips"><a class="chip chip-link" href="../#kw=sonar%20imagery">sonar imagery</a> <a class="chip chip-link" href="../#kw=vision-language">vision-language</a> <a class="chip chip-link" href="../#kw=seafloor%20mapping">seafloor mapping</a> <a class="chip chip-link" href="../#kw=segmentation">segmentation</a> <a class="chip chip-link" href="../#kw=QA">QA</a> </div>
<h3>Citation</h3>

- Kien X. Nguyen, Fengchun Qiao, Arthur Trembanis, and Xi Peng. Seafloorai: a large-scale vision-language dataset for seafloor geological survey. 2024. URL: https://arxiv.org/abs/2411.00172, arXiv:2411.00172.

<pre><code class="language-bibtex">@misc{nguyen2024seafloor,
  archiveprefix = {arXiv},
  author = {Kien X. Nguyen and Fengchun Qiao and Arthur Trembanis and Xi Peng},
  eprint = {2411.00172},
  primaryclass = {cs.CV},
  title = {SeafloorAI: A Large-scale Vision-Language Dataset for Seafloor Geological Survey},
  url = {https://arxiv.org/abs/2411.00172},
  year=2024
}</code></pre>
<h3>Ratings</h3>
<div class="ratings-grid">
  <div class="ratings-head ratings-cell"><span>Category</span><span>Rating</span></div>
  <div class="rating-item">  <div class="rating-cat">Software</div>  <div class="rating-badge">3.00</div>  <div class="rating-bar"><span style="width:60%"></span></div>  <div class="rating-reason">Data processing code is publicly available, but no full benchmark framework or
runnable model implementations are provided yet.
</div></div><div class="rating-item">  <div class="rating-cat">Specification</div>  <div class="rating-badge">5.00</div>  <div class="rating-bar"><span style="width:100%"></span></div>  <div class="rating-reason">Tasks (image segmentation and vision-language QA) are clearly defined with
geospatial and multimodal objectives well specified.
</div></div><div class="rating-item">  <div class="rating-cat">Dataset</div>  <div class="rating-badge">5.00</div>  <div class="rating-bar"><span style="width:100%"></span></div>  <div class="rating-reason">Large-scale, well-annotated sonar imagery dataset with segmentation masks
and natural language descriptions; curated with domain experts.
</div></div><div class="rating-item">  <div class="rating-cat">Metrics</div>  <div class="rating-badge">5.00</div>  <div class="rating-bar"><span style="width:100%"></span></div>  <div class="rating-reason">Standard segmentation pixel accuracy and QA accuracy metrics are clearly specified
and appropriate for the tasks.
</div></div><div class="rating-item">  <div class="rating-cat">Reference Solution</div>  <div class="rating-badge">4.00</div>  <div class="rating-bar"><span style="width:80%"></span></div>  <div class="rating-reason">Some baseline models (e.g., SegFormer, ViLT-style) are mentioned, but
reproducible code or pretrained weights are not fully available yet.
</div></div><div class="rating-item">  <div class="rating-cat">Documentation</div>  <div class="rating-badge">4.00</div>  <div class="rating-bar"><span style="width:80%"></span></div>  <div class="rating-reason">Dataset description and data processing instructions are provided,
but tutorials and benchmark usage guides are limited.
</div></div>
</div>
<div class="avg-rating">  <strong>Average rating:</strong> <span class="badge badge--ok badge--sm">4.33/5</span></div><h3>Radar plot</h3>

<div class="radar-wrap"><img class="radar-img" alt="SeafloorAI radar" src="../../../tex/images/seafloorai_radar.png" /></div>

<p><strong>Edit:</strong> <a href="https://github.com/mlcommons-science/benchmark/tree/main/source">edit this entry</a></p>
