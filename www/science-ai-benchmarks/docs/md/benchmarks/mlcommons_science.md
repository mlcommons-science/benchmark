# MLCommons Science

<p><a class="md-button back-link" href="../">← Back to all benchmarks</a></p>
<div class="info-block meta-block">
  <p class="meta-row"><span class="meta-label">Date</span><span class="meta-sep">:</span> <span class="meta-value">2023-06-01</span></p>
  <p class="meta-row"><span class="meta-label">Name</span><span class="meta-sep">:</span> <span class="meta-value">MLCommons Science</span></p>
  <p class="meta-row"><span class="meta-label">Domain</span><span class="meta-sep">:</span> <span class="meta-value">Earthquake, Satellite Image, Drug Discovery, Electron Microscope, CFD</span></p>
  <p class="meta-row"><span class="meta-label">Focus</span><span class="meta-sep">:</span> <span class="meta-value">AI benchmarks for scientific applications including time-series, imaging, and simulation</span></p>
  <p class="meta-row"><span class="meta-label">Task Types</span><span class="meta-sep">:</span> <span class="meta-value">Time-series analysis, Image classification, Simulation surrogate modeling</span></p>
  <p class="meta-row"><span class="meta-label">Metrics</span><span class="meta-sep">:</span> <span class="meta-value">MAE, Accuracy, Speedup vs simulation</span></p>
  <p class="meta-row"><span class="meta-label">Models</span><span class="meta-sep">:</span> <span class="meta-value">CNN, GNN, Transformer</span></p>
</div>
<h3>Keywords</h3>

<div class="chips"><a class="chip chip-link" href="../#kw=science%20AI">science AI</a> <a class="chip chip-link" href="../#kw=benchmark">benchmark</a> <a class="chip chip-link" href="../#kw=MLCommons">MLCommons</a> <a class="chip chip-link" href="../#kw=HPC">HPC</a> </div>
<h3>Citation</h3>

- Jeyan Thiyagalingam, Gregor von Laszewski, Junqi Yin, Murali Emani, Juri Papay, Gregg Barrett, Piotr Luszczek, Aristeidis Tsaris, Christine Kirkpatrick, Feiyi Wang, Tom Gibbs, Venkatram Vishwanath, Mallikarjun Shankar, Geoffrey Fox, and Tony Hey. Ai benchmarking for science: efforts from the mlcommons science working group. In Hartwig Anzt, Amanda Bienz, Piotr Luszczek, and Marc Baboulin, editors, High Performance Computing. ISC High Performance 2022 International Workshops, 47–64. Cham, 2022. Springer International Publishing.

<pre><code class="language-bibtex">@InProceedings{10.1007/978-3-031-23220-6_4,
  author=&quot;Thiyagalingam, Jeyan
  and von Laszewski, Gregor
  and Yin, Junqi
  and Emani, Murali
  and Papay, Juri
  and Barrett, Gregg
  and Luszczek, Piotr
  and Tsaris, Aristeidis
  and Kirkpatrick, Christine
  and Wang, Feiyi
  and Gibbs, Tom
  and Vishwanath, Venkatram
  and Shankar, Mallikarjun
  and Fox, Geoffrey
  and Hey, Tony&quot;,
  editor=&quot;Anzt, Hartwig
  and Bienz, Amanda
  and Luszczek, Piotr
  and Baboulin, Marc&quot;,
  title=&quot;AI Benchmarking for Science: Efforts from the MLCommons Science Working Group&quot;,
  booktitle=&quot;High Performance Computing. ISC High Performance 2022 International Workshops&quot;,
  year=&quot;2022&quot;,
  publisher=&quot;Springer International Publishing&quot;,
  address=&quot;Cham&quot;,
  pages=&quot;47--64&quot;,
  abstract=&quot;With machine learning (ML) becoming a transformative tool for science, the scientific community needs a clear catalogue of ML techniques, and their relative benefits on various scientific problems, if they were to make significant advances in science using AI. Although this comes under the purview of benchmarking, conventional benchmarking initiatives are focused on performance, and as such, science, often becomes a secondary criteria.&quot;,
  isbn=&quot;978-3-031-23220-6&quot;
}</code></pre>
<h3>Ratings</h3>
<div class="ratings-grid">
  <div class="ratings-head ratings-cell"><span>Category</span><span>Rating</span></div>
  <div class="rating-item">  <div class="rating-cat">Software</div>  <div class="rating-badge">5.00</div>  <div class="rating-bar"><span style="width:100%"></span></div>  <div class="rating-reason">Actively maintained GitHub repository available at https://github.com/mlcommons/science
with implementations, scripts, and reproducibility support.
</div></div><div class="rating-item">  <div class="rating-cat">Specification</div>  <div class="rating-badge">5.00</div>  <div class="rating-bar"><span style="width:100%"></span></div>  <div class="rating-reason">All five specification aspects are covered: system constraints, task, dataset format,
benchmark inputs, and outputs.
</div></div><div class="rating-item">  <div class="rating-cat">Dataset</div>  <div class="rating-badge">5.00</div>  <div class="rating-bar"><span style="width:100%"></span></div>  <div class="rating-reason">Public scientific datasets are used with defined splits. At least 4 FAIR principles
are followed.
</div></div><div class="rating-item">  <div class="rating-cat">Metrics</div>  <div class="rating-badge">5.00</div>  <div class="rating-bar"><span style="width:100%"></span></div>  <div class="rating-reason">Clearly defined metrics such as accuracy, training time, and GPU utilization are
used. These metrics are explained and effectively capture solution performance.
</div></div><div class="rating-item">  <div class="rating-cat">Reference Solution</div>  <div class="rating-badge">5.00</div>  <div class="rating-bar"><span style="width:100%"></span></div>  <div class="rating-reason">A reference implementation is available, well-documented, trainable/open, and includes
full metric evaluation and software/hardware details.
</div></div><div class="rating-item">  <div class="rating-cat">Documentation</div>  <div class="rating-badge">5.00</div>  <div class="rating-bar"><span style="width:100%"></span></div>  <div class="rating-reason">Thorough documentation exists covering the task, background, motivation, evaluation
criteria, and includes a supporting paper.
</div></div>
</div>
<div class="avg-rating">  <strong>Average rating:</strong> <span class="badge badge--ok badge--sm">5.00/5</span></div><h3>Radar plot</h3>

<div class="radar-wrap"><img class="radar-img" alt="MLCommons Science radar" src="../../../tex/images/mlcommons_science_radar.png" /></div>

<p><strong>Edit:</strong> <a href="https://github.com/mlcommons-science/benchmark/tree/main/source">edit this entry</a></p>
