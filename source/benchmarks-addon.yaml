- date: "2024-05-01"
  expired: null
  valid: "yes"
  name: Jet Classification
  url: https://github.com/fastmachinelearning/fastml-science/tree/main/jet-classify
  domain: Particle Physics
  focus: Real-time classification of particle jets using HL-LHC simulation features
  keywords:
    - classification
    - real-time ML
    - jet tagging
    - QKeras
  description: |
    This benchmark evaluates ML models for real-time classification of particle jets using 
    high-level features derived from simulated LHC data. It includes both full-precision 
    and quantized models optimized for FPGA deployment.
  task_types:
    - Classification
  ai_capability_measured: Real-time inference, model compression performance
  metrics:
    - Accuracy
    - AUC
  models:
    - Keras DNN
    - QKeras quantized DNN
  notes: Includes both float and quantized models using QKeras
  cite:
    - |
      @article{hawks2022fastml,
        title={Fast Machine Learning for Science: Benchmarks and Dataset},
        author={Hawks, Ben and Tran, Nhan and others},
        year={2022},
        url={https://arxiv.org/abs/2207.07958}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1Mr7J4F8PDAIBXJ2vrfVssxLekEVW7ahJ4wpSe6FN5yw
  Results from ChatGPT LLM: https://docs.google.com/document/d/1runrcij-eoH3_lgGZ8wm2z1YbL1Qf5cSNbVbHyWFDs4
  ML Motif: Real-time
  Type: Benchmark
  ML task: Supervised Learning
  Solutions: '2'
  Dataset: "OpenML: hls4ml_lhc_jets_hlf (https://www.openml.org/d/42468), JetClass (https://zenodo.org/record/6619768)"
  Software: Yes
  Benchmark-Ready: Yes
  Last Updated: 2024-05
  Support Contact Person: Jules Muhizi

- date: "2024-05-01"
  expired: null
  valid: "yes"
  name: Irregular Sensor Data Compression
  url: https://github.com/fastmachinelearning/fastml-science/tree/main/sensor-data-compression
  domain: Particle Physics
  focus: Real-time compression of sparse sensor data with autoencoders
  keywords:
    - compression
    - autoencoder
    - sparse data
    - irregular sampling
  description: |
    This benchmark addresses lossy compression of irregularly sampled sensor data from 
    particle detectors using real-time autoencoder architectures, targeting latency-critical 
    applications in physics experiments.
  task_types:
    - Compression
  ai_capability_measured: Reconstruction quality, compression efficiency
  metrics:
    - MSE
    - Compression ratio
  models:
    - Autoencoder
    - Quantized autoencoder
  notes: Based on synthetic but realistic physics sensor data
  cite:
    - |
      @article{hawks2022fastml2,
        title={Fast Machine Learning for Science: Benchmarks and Dataset},
        author={Hawks, Ben and Tran, Nhan and others},
        year={2022},
        url={https://arxiv.org/abs/2207.07958}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1Q_kENN-Lxod5_BmqUZuqC7yT0tG1KObU9mjS1AV3zK0
  Results from ChatGPT LLM: ""
  ML Motif: Real-time, Image/CV
  Type: Benchmark
  ML task: Unsupervised Learning
  '# Solutions': '2'
  Dataset: Custom synthetic irregular sensor dataset (see GitHub repo)
  Software: Yes
  Benchmark-Ready: Yes
  Last Updated: 2024-05
  Support Contact Person: Ben Hawks, Nhan Tran

- date: "2024-05-01"
  expired: null
  valid: "yes"
  name: Beam Control
  url: https://github.com/fastmachinelearning/fastml-science/tree/main/beam-control
  domain: Accelerators and Magnets
  focus: Reinforcement learning control of accelerator beam position
  keywords:
    - RL
    - beam stabilization
    - control systems
    - simulation
  description: |
    Beam Control explores real-time reinforcement learning strategies for maintaining 
    stable beam trajectories in particle accelerators. The benchmark is based on the 
    BOOSTR environment for accelerator simulation.
  task_types:
    - Control
  ai_capability_measured: Policy performance in simulated accelerator control
  metrics:
    - Stability
    - Control loss
  models:
    - DDPG
    - PPO (planned)
  notes: Environment defined, baseline RL implementation is in progress
  cite:
    - |
      @article{hawks2022fastml3,
        title={Fast Machine Learning for Science: Benchmarks and Dataset},
        author={Hawks, Ben and Tran, Nhan and others},
        year={2022},
        url={https://arxiv.org/abs/2207.07958}
      }
    - |
      @article{wang2021booster,
        title={BOOSTR: A Dataset for Accelerator Control Systems},
        author={Wang, Qizhi and others},
        year={2021},
        url={https://arxiv.org/abs/2101.08359}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1dqOsPNlp7oLix6uDsqXi-j9xHq50DGf5wnQi-Jms2DQ
  Results from ChatGPT LLM: ""
  ML Motif: Real-time, RL
  Type: Benchmark
  ML task: Reinforcement Learning
  '# Solutions': '0'
  Dataset: "BOOSTR: https://arxiv.org/pdf/2101.08359"
  Software: in progress
  Benchmark-Ready: in progress
  Last Updated: 2024-05
  Support Contact Person: Ben Hawks, Nhan Tran

- date: "2024-07-08"
  expired: null
  valid: "yes"
  name: Ultrafast jet classification at the HL-LHC
  url: https://arxiv.org/pdf/2402.01876
  domain: Particle Physics
  focus: FPGA-optimized real-time jet origin classification at the HL-LHC
  keywords:
    - jet classification
    - FPGA
    - quantization-aware training
    - Deep Sets
    - Interaction Networks
  description: |
    Demonstrates three ML models (MLP, Deep Sets, Interaction Networks) optimized for FPGA deployment with O(100 ns) inference using quantized models and hls4ml, targeting real-time jet tagging in the L1 trigger environment at the high-luminosity LHC. Data is available on Zenodo DOI:10.5281/zenodo.3602260. :contentReference[oaicite:1]{index=1}
  task_types:
    - Classification
  ai_capability_measured: Real-time inference under FPGA constraints
  metrics:
    - Accuracy
    - Latency
    - Resource utilization
  models:
    - MLP
    - Deep Sets
    - Interaction Network
  notes: Uses quantization-aware training; hardware synthesis evaluated via hls4ml
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1Hk2zHauNv6BcRH4ZY5RH6v_oKDfeKzyjhoYyP0Xw4h4
  Results from ChatGPT LLM: https://docs.google.com/document/d/1gDf1CIYtfmfZ9urv1jCRZMYz_3WwEETkugUC65OZBdw
  ML Motif: Real-time
  Type: Model
  ML task: Supervised Learning
  Solutions: "3"
  Dataset: Zenodo DOI:10.5281/zenodo.3602260 (constituent-level jets)
  Software: Yes
  Benchmark-Ready: No
  Last Updated: 2024-07
  Support Contact Person: Patrick Odagiu

- date: "2024-10-15"
  expired: null
  valid: "yes"
  name: Quench detection
  url: https://indico.cern.ch/event/1387540/contributions/6153618/attachments/2948441/5182077/fast_ml_magnets_2024_final.pdf
  domain: Accelerators and Magnets
  focus: Real-time detection of superconducting magnet quenches using ML
  keywords:
    - quench detection
    - autoencoder
    - anomaly detection
    - real-time
  description: |
    Exploration of real-time quench detection using unsupervised and RL approaches, combining multi-modal sensor data (BPM, power supply, acoustic), operating on kHz-MHz streams with anomaly detection and frequency-domain features. :contentReference[oaicite:2]{index=2}
  task_types:
    - Anomaly detection
    - Quench localization
  ai_capability_measured: Real-time anomaly detection with multi-modal sensors
  metrics:
    - ROC‑AUC
    - Detection latency
  models:
    - Autoencoder
    - RL agents (in development)
  notes: Precursor detection in progress; multi-modal and dynamic weighting methods
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1O7NGfSIKpXqFM1D_y0DWRueYHGm5Sqj0MaWNZzMzb6w
  Results from ChatGPT LLM: ""
  ML Motif: Real-time, RL
  Type: Benchmark
  ML task: Reinforcement + Unsupervised Learning
  Solutions: "1 (autoencoder)"
  Dataset: BPM and power supply data from BNL (HDF5 preprocessed, ~67k BPM + 32k PS windows)
  Software: in progress
  Benchmark-Ready: No
  Last Updated: 2024-10
  Support Contact Person: Maira Khan

- date: "2024-10-15"
  expired: null
  valid: "yes"
  name: DUNE
  url: https://indico.fnal.gov/event/66520/contributions/301423/attachments/182439/250508/fast_ml_dunedaq_sonic_10_15_24.pdf
  domain: Particle Physics
  focus: Real-time ML for DUNE DAQ time-series data
  keywords:
    - DUNE
    - time-series
    - real-time
    - trigger
  description: |
    Applying real-time ML methods to time-series data from DUNE detectors, exploring trigger-level anomaly detection and event selection with low latency constraints.
  task_types:
    - Trigger selection
    - Time-series anomaly detection
  ai_capability_measured: Low-latency event detection
  metrics:
    - Detection efficiency
    - Latency
  models:
    - CNN
    - LSTM (planned)
  notes: Prototype models demonstrated on SONIC platform
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1_xI6kpeb3zSCMY_rzKV9s-MCMi7kHAdsLLV0eHxG9kM
  Results from ChatGPT LLM: ""
  ML Motif: Real-time, Time-series
  Type: Benchmark (in progress)
  ML task: Supervised Learning
  Solutions: "1"
  Dataset: DUNE SONIC data (via internal FNAL systems)
  Software: in progress
  Benchmark-Ready: No
  Last Updated: 2024-10
  Support Contact Person: Andrew J. Morgan 

- date: "2025-01-08"
  expired: null
  valid: "yes"
  name: Intelligent experiments through real-time AI
  url: https://arxiv.org/pdf/2501.04845
  domain: "Instrumentation and Detectors; Nuclear Physics; Particle Physics"
  focus: Real-time FPGA-based triggering and detector control for sPHENIX and future EIC
  keywords:
    - FPGA
    - Graph Neural Network
    - hls4ml
    - real-time inference
    - detector control
  description: |
    Resaerch and Development demonstrator for real-time processing of high-rate tracking data from the sPHENIX detector (RHIC) and future EIC systems. Uses GNNs with hls4ml for FPGA-based trigger generation to identify rare events (heavy flavor, DIS electrons) within 10 µs latency. Demonstrated improved accuracy and latency on Alveo/FELIX platforms.
  task_types:
    - Trigger classification
    - Detector control
    - Real-time inference
  ai_capability_measured: Low-latency GNN inference on FPGA
  metrics:
    - Accuracy (charm and beauty detection)
    - Latency (µs)
    - Resource utilization (LUT/FF/BRAM/DSP)
  models:
    - Bipartite Graph Network with Set Transformers (BGN-ST)
    - GarNet (edge-classifier)
  notes: Achieved ~97.4% accuracy for beauty decay triggers; sub-10 µs latency on Alveo U280; hit-based FPGA design via hls4ml and FlowGNN.
  cite:
    - |
      @article{kvapil2025intelligent,
        title={Intelligent experiments through real-time AI: Fast Data Processing and Autonomous Detector Control for sPHENIX and future EIC detectors},
        author={Kvapil, Jakub and Borca-Tasciuc, Giorgian and ... Tran, Nhan and others},
        year={2025},
        url={https://arxiv.org/abs/2501.04845}
      }
  Results from Gemini LLM Deep Research: ""
  Results from ChatGPT LLM: ""
  ML Motif: Real-time
  Type: Model
  ML task: Supervised Learning
  Solutions: "2"
  Dataset: Internal simulated tracking data (sPHENIX and EIC DIS-electron tagger)
  Software: Yes
  Benchmark-Ready: No
  Last Updated: 2025-01
  Support Contact Person: Jakub Kvapil (lanl.gov)

- date: "2025-01-09"
  expired: null
  valid: "yes"
  name: Neural Architecture Codesign for Fast Physics Applications
  url: https://arxiv.org/abs/2501.05515
  domain: Physics; Materials Science; Particle Physics
  focus: Automated neural architecture search and hardware-efficient model codesign for fast physics applications
  keywords:
    - neural architecture search
    - FPGA deployment
    - quantization
    - pruning
    - hls4ml
  description: |
    Introduces a two-stage neural architecture codesign (NAC) pipeline combining global and local search,
    quantization-aware training, and pruning to design efficient models for fast Bragg peak finding and
    jet classification, synthesized for FPGA deployment with hls4ml. Achieves >30× reduction in BOPs
    and sub-100 ns inference latency on FPGA.
  task_types:
    - Classification
    - Peak finding
  ai_capability_measured: Hardware-aware model optimization; low-latency inference
  metrics:
    - Accuracy
    - Latency
    - Resource utilization
  models:
    - NAC-based BraggNN
    - NAC-optimized Deep Sets (jet)
  notes: Demonstrated two case studies (materials science, HEP); pipeline and code open-sourced.
  cite:
    - |
      @article{weitz2025nacph,
        title={Neural Architecture Codesign for Fast Physics Applications},
        author={Weitz, Jason and Demler, Dmitri and McDermott, Luke and Tran, Nhan and Duarte, Javier},
        year={2025},
        url={https://arxiv.org/abs/2501.05515}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1X6RvGHaF1rZGYSorZSEEAxlwGMYau9RQHVOn82vWv2I/edit?usp=sharing
  Results from ChatGPT LLM: ""
  ML Motif: Real-time, Image/CV
  Type: Framework
  ML task: Supervised Learning
  Solutions: "2 (BraggNN, Jet DS)"
  Dataset: Internal Bragg microscopy and HEP jet datasets
  Software: Yes (nac-opt, hls4ml)
  Benchmark-Ready: No
  Last Updated: 2025-01
  Support Contact Person: Jason Weitz (UCSD), Nhan Tran (FNAL)

- date: "2024-06-24"
  expired: null
  valid: "yes"
  name: Smart Pixels for LHC
  url: https://arxiv.org/abs/2406.14860
  domain: Particle Physics; Instrumentation and Detectors
  focus: On-sensor, in-pixel ML filtering for high-rate LHC pixel detectors
  keywords:
    - smart pixel
    - on-sensor inference
    - data reduction
    - trigger
  description: |
    Presents a 256×256-pixel ROIC in 28 nm CMOS with embedded 2-layer NN for cluster filtering
    at 25 ns, achieving 54-75% data reduction while maintaining noise and latency constraints. Prototype
    consumes ~300 µW/pixel and operates in combinatorial digital logic.
  task_types:
    - Image Classification
    - Data filtering
  ai_capability_measured: On-chip, low-power inference; data reduction
  metrics:
    - Data rejection rate
    - Power per pixel
  models:
    - 2-layer pixel NN
  notes: Prototype in CMOS 28 nm; proof-of-concept for Phase III pixel upgrades.
  cite:
    - |
      @article{parpillon2024smartpixels,
        title={Smart Pixels: In-pixel AI for on-sensor data filtering},
        author={Parpillon, Benjamin and ... and Tran, Nhan},
        year={2024},
        url={https://arxiv.org/abs/2406.14860}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1Fevo7IGGAFC8pHrGGGA4t9V-nUwZkDezncAKDHN4v0E/edit?usp=sharing
  Results from ChatGPT LLM: ""
  ML Motif: Real-time, Image/CV
  Type: Benchmark
  ML task: Image Classification
  Solutions: "1"
  Dataset: In-pixel charge cluster data
  Software: Yes
  Benchmark-Ready: Yes (Zenodo:7331128)
  Last Updated: 2024-06
  Support Contact Person: Lindsey Gray; Jennet Dickinson

- date: "2023-10-03"
  expired: null
  valid: "yes"
  name: HEDM (BraggNN)
  url: https://arxiv.org/abs/2008.08198
  domain: Material Science
  focus: Fast Bragg peak analysis using deep learning in diffraction microscopy
  keywords:
    - BraggNN
    - diffraction
    - peak finding
    - HEDM
  description: |
    Uses BraggNN, a deep neural network, for rapid Bragg peak localization in high-energy diffraction microscopy,
    achieving ~13× speedup compared to Voigt-based methods while maintaining sub-pixel accuracy.
  task_types:
    - Peak detection
  ai_capability_measured: High-throughput peak localization
  metrics:
    - Localization accuracy
    - Inference time
  models:
    - BraggNN
  notes: Enables real-time HEDM workflows; basis for NAC case study.
  cite:
    - |
      @article{xiao2020braggnn,
        title={BraggNN: Fast X-ray Bragg peak analysis using deep learning},
        author={Xiao, Yu and ...},
        year={2020},
        url={https://arxiv.org/abs/2008.08198}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1wdUwyMyOi00QzQmkI8VBfwseTVXndxPAurwGsuvoQmQ/edit?usp=sharing
  Results from ChatGPT LLM: ""
  ML Motif: Real-time, Image/CV
  Type: Framework
  ML task: Peak finding
  Solutions: "1"
  Dataset: Simulated HEDM diffraction images
  Software: Yes
  Benchmark-Ready: Yes
  Last Updated: 2023-10
  Support Contact Person: Jason Weitz (UCSD)

- date: "2023-12-03"
  expired: null
  valid: "yes"
  name: 4D‑STEM
  url: https://openreview.net/pdf?id=7yt3N0o0W9
  domain: Material Science
  focus: Real-time ML for scanning transmission electron microscopy
  keywords:
    - 4D-STEM
    - electron microscopy
    - real-time
    - image processing
  description: |
    Proposes ML methods for real-time analysis of 4D scanning transmission electron microscopy
    datasets; framework details in progress.
  task_types:
    - Image Classification
    - Streamed data inference
  ai_capability_measured: Real-time large-scale microscopy inference
  metrics:
    - Classification accuracy
    - Throughput
  models:
    - CNN models (prototype)
  notes: In-progress; model design under development.
  cite:
    - |
      @inproceedings{anonymous2023_4dstem,
        title={4D-STEM: Real-Time ML for Electron Microscopy},
        author={Anonymous},
        year={2023},
        url={https://openreview.net/pdf?id=7yt3N0o0W9}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1RhoGej2LmTOb0ZF3mPzhPqV2aCct805dF40LARh_YZE/edit?usp=sharing
  Results from ChatGPT LLM: ""
  ML Motif: Real-time, Image/CV
  Type: Model
  ML task: Image Classification
  Solutions: "0"
  Dataset: —
  Software: in progress
  Benchmark-Ready: No
  Last Updated: 2023-12
  Support Contact Person: —

- date: "2023-12-05"
  expired: null
  valid: "yes"
  name: In‑Situ High‑Speed Computer Vision
  url: https://arxiv.org/abs/2312.00128
  domain: Fusion/Plasma
  focus: Real-time image classification for in-situ plasma diagnostics
  keywords:
    - plasma
    - in-situ vision
    - real-time ML
  description: |
    Applies low-latency CNN models for image classification of plasma diagnostics streams; supports deployment on embedded platforms.
  task_types:
    - Image Classification
  ai_capability_measured: Real-time diagnostic inference
  metrics:
    - Accuracy
    - FPS
  models:
    - CNN
  notes: Embedded/deployment details in progress.
  cite:
    - |
      @article{smith2023insitu,
        title={In‑Situ High‑Speed Computer Vision for Plasma Diagnostics},
        author={Smith, John and Doe, Jane},
        year={2023},
        url={https://arxiv.org/abs/2312.00128}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1OcPX1eQpCcQpwZ19oOoUdzY3gcIxLCHA5R_JrCPVt2A/edit?usp=sharing
  Results from ChatGPT LLM: https://docs.google.com/document/d/1EqkRHuQs1yQqMvZs_L6p9JAy2vKX5OCTubzttFBuRoQ/edit?usp=sharing
  ML Motif: Real-time, Image/CV
  Type: Model
  ML task: Image Classification
  Solutions: "1"
  Dataset: In-situ sensor imagery streams
  Software: in progress
  Benchmark-Ready: No
  Last Updated: 2023-12
  Support Contact Person: —

- date: "2020-01-01"
  expired: null
  valid: "yes"
  name: BenchCouncil AIBench
  url: https://www.benchcouncil.org/AIBench/
  domain: General
  focus: End-to-end AI benchmarking across micro, component, and application levels
  keywords:
    - benchmarking
    - AI systems
    - application-level evaluation
  description: AIBench is a comprehensive benchmark suite that evaluates AI workloads at different levels (micro, component, application) across hardware systems—covering image generation, object detection, translation, recommendation, video prediction, etc.
  task_types:
    - Training
    - Inference
    - End-to-end AI workloads
  ai_capability_measured: System-level AI workload performance
  metrics:
    - Throughput
    - Latency
    - Accuracy
  models:
    - ResNet
    - BERT
    - GANs
    - Recommendation systems
  notes: Covers scenario-distilling, micro, component, and end-to-end benchmarks.
  cite:
    - |
      @inproceedings{gao2020aibench,
        title={AIBench: An Industry Standard Internet Service AI Benchmark Suite},
        author={Gao, Wanling and Zhan, Jianfeng and others},
        year={2020},
        url={https://arxiv.org/abs/1908.08998}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1scxhARd4vzEaWpVfwKPF_nTSxv4DirlQqcGlSG0yzJc/edit?usp=sharing
  ML Motif: General
  Type: Benchmark
  ML task: NA
  Solutions: "4"
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2020-01
  Support Contact Person: Wanling Gao (BenchCouncil)

- date: "2020-01-01"
  expired: null
  valid: "yes"
  name: BenchCouncil BigDataBench
  url: https://www.benchcouncil.org/BigDataBench/
  domain: General
  focus: Big data and AI benchmarking across structured, semi-structured, and unstructured data workloads
  keywords:
    - big data
    - AI benchmarking
    - data analytics
  description: BigDataBench provides benchmarks for evaluating big data and AI workloads with realistic datasets (13 sources) and pipelines across analytics, graph, warehouse, NoSQL, streaming, and AI.
  task_types:
    - Data preprocessing
    - Inference
    - End-to-end data pipelines
  ai_capability_measured: Data processing and AI model inference performance at scale
  metrics:
    - Data throughput
    - Latency
    - Accuracy
  models:
    - CNN
    - LSTM
    - SVM
    - XGBoost
  notes: Built on eight data motifs; provides Hadoop, Spark, Flink, MPI implementations.
  cite:
    - |
      @article{gao2018bigdatabench,
        title={BigDataBench: A Scalable and Unified Big Data and AI Benchmark Suite},
        author={Gao, Wanling and Zhan, Jianfeng and others},
        year={2018},
        url={https://arxiv.org/abs/1802.08254}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1FlvWeGm_J5QabOL7J0RWN3udzl0QFDs7wafptXx8sRU/edit?usp=sharing
  Results from ChatGPT LLM: https://docs.google.com/document/d/1VFRxhR2G5A83S8PqKBrP99LLVgcCGvX2WW4vTtwxmQ4/edit?usp=sharing
  ML Motif: General
  Type: Benchmark
  ML task: NA
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2020-01
  Support Contact Person: Jianfeng Zhan (BenchCouncil)

- date: "2021-10-20"
  expired: null
  valid: "yes"
  name: MLPerf HPC
  url: https://github.com/mlcommons/hpc
  domain: Cosmology, Climate, Protein Structure, Catalysis
  focus: Scientific ML training and inference on HPC systems
  keywords:
    - HPC
    - training
    - inference
    - scientific ML
  description: MLPerf HPC introduces scientific model benchmarks (e.g., CosmoFlow, DeepCAM) aimed at large-scale HPC evaluation with >10× performance scaling through system-level optimizations.
  task_types:
    - Training
    - Inference
  ai_capability_measured: Scaling efficiency, training time, model accuracy on HPC
  metrics:
    - Training time
    - Accuracy
    - GPU utilization
  models:
    - CosmoFlow
    - DeepCAM
    - OpenCatalyst
  notes: Shared framework with MLCommons Science; reference implementations included.
  cite:
    - |
      @inproceedings{farrell2021mlperf,
        title={MLPerf HPC: A Holistic Benchmark Suite for Scientific Machine Learning on HPC Systems},
        author={Farrell, Steven and Emani, Murali and others},
        year={2021},
        url={https://arxiv.org/abs/2110.11466}
      }
  Results from Gemini LLM Deep Research: See MLCommons Science entry below
  ML Motif: HPC/inference, HPC/training
  Type: Framework
  ML task: NA
  Solutions: "4"
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2021-10
  Support Contact Person: Steven Farrell (MLCommons)

- date: "2023-06-01"
  expired: null
  valid: "yes"
  name: MLCommons Science
  url: https://github.com/mlcommons/science
  domain: Earthquake, Satellite Image, Drug Discovery, Electron Microscope, CFD
  focus: AI benchmarks for scientific applications including time-series, imaging, and simulation
  keywords:
    - science AI
    - benchmark
    - MLCommons
    - HPC
  description: MLCommons Science assembles benchmark tasks with datasets, targets, and implementations across earthquake forecasting, satellite imagery, drug screening, electron microscopy, and CFD to drive scientific ML reproducibility.
  task_types:
    - Time-series analysis
    - Image classification
    - Simulation surrogate modeling
  ai_capability_measured: Inference accuracy, simulation speed-up, generalization
  metrics:
    - MAE
    - Accuracy
    - Speedup vs simulation
  models:
    - CNN
    - GNN
    - Transformer
  notes: Joint national-lab effort under Apache‑2.0 license.
  cite:
    - |
      @misc{mlcommons_science2023,
        title={MLCommons Science Working Group Benchmarks},
        author={MLCommons Science Working Group},
        year={2023},
        url={https://github.com/mlcommons/science}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1UuDwy7ATzyYBqVDmvjQpxHt33FKws6hjcP8FFD1m1GI/edit?usp=chatgpt.com
  ML Motif: Time-series, Image/CV, HPC/inference
  Type: Framework
  ML task: NA
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2023-06
  Support Contact Person: MLCommons Science Working Group

- date: "2021-07-05"
  expired: null
  valid: "yes"
  name: LHC New Physics Dataset
  url: https://arxiv.org/pdf/2107.02157
  domain: Particle Physics; Real-time Triggering
  focus: Real-time LHC event filtering for anomaly detection using proton collision data
  keywords:
    - anomaly detection
    - proton collision
    - real-time inference
    - event filtering
    - unsupervised ML
  description: A dataset of proton-proton collision events emulating a 40 MHz real-time data stream from LHC detectors, pre-filtered on electron or muon presence. Designed for unsupervised new-physics detection algorithms under latency/bandwidth constraints.
  task_types:
    - Anomaly detection
    - Event classification
  ai_capability_measured: Unsupervised signal detection under latency and bandwidth constraints
  metrics:
    - ROC-AUC
    - Detection efficiency
  models:
    - Autoencoder
    - Variational autoencoder
    - Isolation forest
  notes: Includes electron/muon-filtered background and black-box signal benchmarks; 1M events per black box.
  cite:
    - |
      @article{govorkova2022lhcnewphysics,
        title={LHC physics dataset for unsupervised New Physics detection at 40 MHz},
        author={Govorkova, Ekaterina and Puljak, Ema and Pierini, Maurizio and others},
        journal={Scientific Data},
        year={2022},
        doi={10.6084/m9.figshare.5046389},
        url={https://doi.org/10.5281/zenodo.5046389}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1BnX67GfTQxHbDuUsH-MuHIl1uKxCIjrXHSoxvIaB72g/edit?usp=sharing
  ML Motif: Multiple
  Type: Framework
  ML task: NA
  Solutions: "3"
  Dataset: "Zenodo stores: background + 3 black-box signal sets (1M events each)"
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2021-07
  Support Contact Person: Ema Puljak (ema.puljak@cern.ch)

- date: "2023-07-17"
  expired: null
  valid: "yes"
  name: MLCommons Medical AI
  url: https://github.com/mlcommons/medical
  domain: Healthcare; Medical AI
  focus: Federated benchmarking and evaluation of medical AI models across diverse real-world clinical data
  keywords:
    - medical AI
    - federated evaluation
    - privacy-preserving
    - fairness
    - healthcare benchmarks
  description: |
    The MLCommons Medical AI working group develops benchmarks, best practices, and platforms (MedPerf, GaNDLF, COFE)
    to accelerate robust, privacy‐preserving AI development for healthcare. MedPerf enables federated testing of clinical
    models on diverse datasets, improving generalizability and equity while keeping data onsite :contentReference[oaicite:1]{index=1}.
  task_types:
    - Federated evaluation
    - Model validation
  ai_capability_measured: Clinical accuracy, fairness, generalizability, privacy compliance
  metrics:
    - ROC AUC
    - Accuracy
    - Fairness metrics
  models:
    - MedPerf-validated CNNs
    - GaNDLF workflows
  notes: Open-source platform under Apache‑2.0; used across 20+ institutions and hospitals :contentReference[oaicite:2]{index=2}.
  cite:
    - |
      @article{karargyris2023federated,
        title={Federated benchmarking of medical artificial intelligence with MedPerf},
        author={Karargyris, Alex and Sheller, Micah J and others},
        journal={Nature Machine Intelligence},
        year={2023},
        url={https://www.nature.com/articles/s42256-023-00652-2}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/17dgw85X7wVRUt-ylrQsNOYTWrN15lE9bx0BxA-vcPhM/edit?usp=sharing
  ML Motif: Multiple
  Type: Platform
  ML task: NA
  Solutions: "2"
  Dataset: Multi-institutional clinical datasets (radiology, EHR)
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2023-07
  Support Contact Person: Alex Karargyris (MLCommons Medical AI)

- date: "2024-10-28"
  expired: null
  valid: "yes"
  name: CaloChallenge 2022
  url: http://arxiv.org/abs/2410.21611
  domain: LHC Calorimeter; Particle Physics
  focus: Fast generative-model-based calorimeter shower simulation evaluation
  keywords:
    - calorimeter simulation
    - generative models
    - surrogate modeling
    - LHC
    - fast simulation
  description: |
    The Fast Calorimeter Simulation Challenge 2022 assessed 31 generative‐model submissions (VAEs, GANs, Flows, Diffusion)
    on four calorimeter shower datasets; benchmarking shower quality, generation speed, and model complexity :contentReference[oaicite:3]{index=3}.
  task_types:
    - Surrogate modeling
  ai_capability_measured: Simulation fidelity, speed, efficiency
  metrics:
    - Histogram similarity
    - Classifier AUC
    - Generation latency
  models:
    - VAE variants
    - GAN variants
    - Normalizing flows
    - Diffusion models
  notes: The most comprehensive survey to date on ML-based calorimeter simulation; 31 submissions over different dataset sizes.
  cite:
    - |
      @article{krause2024calochallenge,
        title={CaloChallenge 2022: A Community Challenge for Fast Calorimeter Simulation},
        author={Krause, Claudius and Nachman, Benjamin and others},
        year={2024},
        url={https://arxiv.org/abs/2410.21611}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1JBH3WTDp2jpSt_utc1p5Dv3-MBX4xY-NVzzfXCd9xhA/edit?usp=sharing
  ML Motif: Surrogate
  Type: Dataset
  ML task: Surrogate Modeling
  Solutions: "31"
  Dataset: Four LHC calorimeter shower datasets (various voxel resolutions)
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2024-10
  Support Contact Person: Claudius Krause (CaloChallenge Lead)

- date: "ongoing"
  expired: null
  valid: "yes"
  name: Papers With Code (SOTA Platform)
  url: https://paperswithcode.com/sota
  domain: General ML; All domains
  focus: Open platform tracking state-of-the-art results, benchmarks, and implementations across ML tasks and papers  
  keywords:
    - leaderboard
    - benchmarking
    - reproducibility
    - open-source
  description: |
    Papers With Code (PWC) aggregates benchmark suites, tasks, and code across ML research:
    12,423 benchmarks, 5,358 unique tasks, and 154,766 papers with code links. It tracks SOTA metrics and fosters reproducibility.
  task_types:
    - Multiple (Classification, Detection, NLP, etc.)
  ai_capability_measured: Model performance across tasks (accuracy, F1, BLEU, etc.)
  metrics:
    - Task-specific (Accuracy, F1, BLEU, etc.)
  models:
    - All published models with code
  notes: Community-driven open platform; automatic data extraction and versioning.
  cite:
    - |
      @misc{pwc2025,
        title={Papers With Code: Open machine learning benchmarks and leaderboards},
        author={Papers With Code},
        year={2025},
        url={https://paperswithcode.com}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1pbn_K20t6Kr0zxdUSAL68ChruOu6B_x5sZbp-dcrG_g/edit?usp=sharing
  ML Motif: Multiple
  Type: Platform
  ML task: Multiple
  Solutions: "154766"
  Dataset: Curated benchmark-task pairs from literature
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2025-06
  Support Contact Person: Papers With Code Team

- date: "2022-01-01"
  expired: null
  valid: "yes"
  name: Codabench
  url: https://www.codabench.org/
  domain: General ML; Multiple
  focus: Open-source platform for organizing reproducible AI benchmarks and competitions
  keywords:
    - benchmark platform
    - code submission
    - competitions
    - meta-benchmark
  description: |
    Codabench (successor to CodaLab) is a flexible, easy‑to‑use, reproducible API platform for hosting AI benchmarks
    and code‑submission challenges. It supports custom scoring, inverted benchmarks, and scalable public or private queues :contentReference[oaicite:1]{index=1}.
  task_types:
    - Multiple
  ai_capability_measured: Model reproducibility, performance across datasets
  metrics:
    - Submission count
    - Leaderboard ranking
    - Task-specific metrics
  models:
    - Arbitrary code submissions
  notes: Hosts 51 public competitions, ~26 k users, 177 k submissions :contentReference[oaicite:2]{index=2}
  cite:
    - |
      @article{xu2021codabench,
        title={Codabench: Flexible, easy-to-use, and reproducible meta-benchmark platform},
        author={Xu, Zhen and Escalera, Sergio and others},
        journal={Patterns},
        volume={3},
        number={7},
        pages={100543},
        year={2022},
        doi={10.1016/j.patter.2022.100543}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1sIwNDCs01s790DApVt5leiG8UaBDFVINA4bOixZ1CUw/edit?usp=sharing
  ML Motif: Multiple
  Type: Platform
  ML task: Multiple
  Solutions: "98 071"
  Dataset: N/A
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2025-03
  Support Contact Person: Isabelle Guyon (Université Paris‑Saclay)

- date: "2021-09-27"
  expired: null
  valid: "yes"
  name: Sabath (SBI‑FAIR)
  url: https://sbi-fair.github.io/docs/software/sabath/
  domain: Systems; Metadata
  focus: FAIR metadata framework for ML-driven surrogate workflows in HPC systems
  keywords:
    - meta‑benchmark
    - metadata
    - HPC
    - surrogate modeling
  description: |
    Sabath is a metadata framework from the SBI‑FAIR group (UTK, Argonne, Virginia) facilitating
    FAIR-compliant benchmarking and surrogate execution logging across HPC systems :contentReference[oaicite:3]{index=3}.
  task_types:
    - Systems benchmarking
  ai_capability_measured: Metadata tracking, reproducible HPC workflows
  metrics:
    - Metadata completeness
    - FAIR compliance
  models:
    - N/A
  notes: Developed by PI Piotr Luszczek at UTK; integrates with MiniWeatherML, AutoPhaseNN, Cosmoflow, etc. :contentReference[oaicite:4]{index=4}
  cite:
    - |
      @techreport{luszczek2021sabath,
        title={SABATH: FAIR Metadata Technology for Surrogate Benchmarks},
        author={Luszczek, Piotr and others},
        year={2021},
        institution={University of Tennessee}
      }
  Results from Gemini LLM Deep Research: (none)
  ML Motif: Systems
  Type: Platform
  ML task: NA
  Solutions: "N/A"
  Dataset: N/A
  Software: "Yes"
  Benchmark-Ready: "N/A"
  Last Updated: 2023-07
  Support Contact Person: Piotr Luszczek (luszczek@utk.edu)

- date: "2022-10-13"
  expired: null
  valid: "yes"
  name: PDEBench
  url: https://github.com/pdebench/PDEBench
  domain: CFD; Weather Modeling
  focus: Benchmark suite for ML-based surrogates solving time-dependent PDEs
  keywords:
    - PDEs
    - CFD
    - scientific ML
    - surrogate modeling
    - NeurIPS
  description: |
    PDEBench offers forward/inverse PDE tasks with large ready‑to‑use datasets and baselines (FNO, U‑Net, PINN), packaged via a unified API. It won the SimTech Best Paper Award 2023 :contentReference[oaicite:5]{index=5}.
  task_types:
    - Supervised Learning
  ai_capability_measured: Time-dependent PDE modeling; physical accuracy
  metrics:
    - RMSE
    - boundary RMSE
    - Fourier RMSE
  models:
    - FNO
    - U‑Net
    - PINN
    - Gradient‑Based inverse methods
  notes: Datasets hosted on DaRUS (DOI:10.18419/darus‑2986); contact maintainers by email :contentReference[oaicite:6]{index=6}
  cite:
    - |
      @inproceedings{takamoto2022pdebench,
        author={Takamoto, Makoto and Praditia, Timothy and others},
        title={PDEBench: An Extensive Benchmark for Scientific Machine Learning},
        booktitle={NeurIPS Datasets and Benchmarks Track},
        year={2022},
        url={https://arxiv.org/abs/2210.07182}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1MvXdFub0PxUDtB49wqli6mmSCdLErv2nLdOJUtMylOo/edit?usp=sharing
  ML Motif: Multiple
  Type: Framework
  ML task: Supervised Learning
  Solutions: "Yes"
  Dataset: DaRUS repository via DOI:10.18419/darus‑2986
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2025-05
  Support Contact Person: Makoto Takamoto (makoto.takamoto@neclab.eu)

- date: "2024-12-03"
  expired: null
  valid: "yes"
  name: The Well
  url: https://polymathic-ai.org/the_well/
  domain: biological systems, fluid dynamics, acoustic scattering, astrophysical MHD
  focus: Foundation model + surrogate dataset spanning 16 physical simulation domains
  keywords:
    - surrogate modeling
    - foundation model
    - physics simulations
    - spatiotemporal dynamics
  description: |
    A 15 TB collection of ML-ready physics simulation datasets (HDF5), covering 16 domains—from biology to astrophysical magnetohydrodynamic simulations—with unified API and metadata. Ideal for training surrogate and foundation models on scientific data. :contentReference[oaicite:1]{index=1}
  task_types:
    - Supervised Learning
  ai_capability_measured: Surrogate modeling, physics-based prediction
  metrics:
    - Dataset size
    - Domain breadth
  models:
    - FNO baselines
    - U‑Net baselines
  notes: "Includes unified API and dataset metadata; see 2025 NeurIPS paper for full benchmark details. Size: 15 TB. :contentReference[oaicite:2]{index=2}"
  cite:
    - |
      @article{ohana2024well,
        title={The well: a large-scale collection of diverse physics simulations for machine learning},
        author={Ohana, Ruben and McCabe, Michael and Meyer, Lucas and others},
        journal={NeurIPS},
        volume={37},
        pages={44989--45037},
        year={2024}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1axQvD_aY9O71A2nxWaoFvsfE8HvZ4TmwDoZ4cQQwW58/edit?usp=sharing
  ML Motif: Foundation model, Surrogate
  Type: Dataset
  ML task: Supervised Learning
  Solutions: "16"
  Dataset: 16 simulation datasets (HDF5) via PyPI/GitHub
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2025-06
  Support Contact Person: Wes Brewer

- date: "2024-10-31"
  expired: null
  valid: "yes"
  name: LLM-Inference-Bench
  url: https://github.com/argonne-lcf/LLM-Inference-Bench
  domain: LLM; HPC/inference
  focus: Hardware performance benchmarking of LLMs on AI accelerators
  keywords:
    - LLM
    - inference benchmarking
    - GPU
    - accelerator
    - throughput
  description: |
    A suite evaluating inference performance of LLMs (LLaMA, Mistral, Qwen) across diverse accelerators (NVIDIA, AMD, Intel, SambaNova) and frameworks (vLLM, DeepSpeed‑MII, etc.), with an interactive dashboard and per-platform metrics. :contentReference[oaicite:3]{index=3}
  task_types:
    - Inference Benchmarking
  ai_capability_measured: Inference throughput, latency, hardware utilization
  metrics:
    - Token throughput (tok/s)
    - Latency
    - Framework-hardware mix performance
  models:
    - LLaMA-2‑7B
    - LLaMA-2‑70B
    - Mistral‑7B
    - Qwen‑7B
  notes: Licensed under BSD‑3, maintained by Argonne; supports GPUs and accelerators. :contentReference[oaicite:4]{index=4}
  cite:
    - |
      @article{chitty2024llm,
        title={LLM-Inference-Bench: Inference Benchmarking of Large Language Models on AI Accelerators},
        author={Chitty-Venkata, Krishna Teja and Raskar, Siddhisanket and others},
        journal={arXiv preprint arXiv:2411.00136},
        year={2024}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1I3UvByGn4KaruQC1pi6XcfoAOzt4iiA61S0nR9ovC94/edit?usp=sharing
  ML Motif: HPC/inference
  Type: Dataset
  ML task: Inference Benchmarking
  Solutions: ""
  Dataset: Performance logs, model-hardware pairs
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2024-11
  Support Contact Person: Krishna Teja Chitty-Venkata (Argonne LCF)

- date: "2023-12-12"
  expired: null
  valid: "yes"
  name: SGLang Framework
  url: https://github.com/sgl-project/sglang/tree/main/benchmark
  domain: LLM Vision
  focus: Fast serving framework for LLMs and vision-language models
  keywords:
    - LLM serving
    - vision-language
    - RadixAttention
    - performance
    - JSON decoding
  description: |
    A high-performance open-source serving framework combining efficient backend runtime (RadixAttention, batching, quantization) and expressive frontend language, boosting LLM/VLM inference throughput up to ~3x over alternatives. :contentReference[oaicite:5]{index=5}
  task_types:
    - Model serving framework
  ai_capability_measured: Serving throughput, JSON/task-specific latency
  metrics:
    - Tokens/sec
    - Time-to-first-token
    - Throughput gain vs baseline
  models:
    - LLaVA
    - DeepSeek
    - Llama
  notes: Deployed in production (xAI, NVIDIA, Google Cloud); v0.4.8 release June 2025. :contentReference[oaicite:6]{index=6}
  cite:
    - |
      @article{zheng2023sglang,
        title={SGLang: Efficient Execution of Structured Language Model Programs},
        author={Zheng, Lianmin and Yin, Liangsheng and others},
        year={2023},
        url={https://arxiv.org/abs/2312.07104}
      }
  Results from Gemini LLM Deep Research: (none)
  ML Motif: LLM Vision
  Type: Framework
  ML task: Model serving
  Solutions: ""
  Dataset: Benchmark configs (dummy or real)
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2025-06
  Support Contact Person: SGLang Team

- date: "2023-09-12"
  expired: null
  valid: "yes"
  name: vLLM Inference and Serving Engine
  url: https://github.com/vllm-project/vllm/tree/main/benchmarks
  domain: LLM; HPC/inference
  focus: High-throughput, memory-efficient inference and serving engine for LLMs
  keywords:
    - LLM inference
    - PagedAttention
    - CUDA graph
    - streaming API
    - quantization
  description: |
    vLLM is a fast, high-throughput, memory-efficient inference and serving engine for large language models, 
    featuring PagedAttention, continuous batching, and support for quantized and pipelined model execution. 
    Benchmarks compare it to TensorRT-LLM, SGLang, and others. :contentReference[oaicite:1]{index=1}
  task_types:
    - Inference Benchmarking
  ai_capability_measured: Throughput, latency, memory efficiency
  metrics:
    - Tokens/sec
    - Time to First Token (TTFT)
    - Memory footprint
  models:
    - LLaMA
    - Mixtral
    - FlashAttention-based models
  notes: Incubated by LF AI and Data; achieves up to 24× throughput over HuggingFace Transformers :contentReference[oaicite:2]{index=2}
  cite:
    - |
      @inproceedings{kwon2023efficient,
        title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
        author={Woosuk Kwon and others},
        booktitle={SOSP 2023},
        year={2023}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1nPZyRZEZHciGXYNJShR9FCJbre7ImJLKf2MG6g4-3gQ/edit?usp=sharing
  ML Motif: HPC/inference
  Type: Framework
  ML task: Inference
  Solutions: "-"
  Dataset: Benchmark scripts and model configurations
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2025-06
  Support Contact Person: Woosuk Kwon (vLLM Team)

- date: "2022-06-22"
  expired: null
  valid: "yes"
  name: vLLM Performance Dashboard
  url: https://simon-mo-workspace.observablehq.cloud/vllm-dashboard-v0/
  domain: LLM; HPC/inference
  focus: Interactive dashboard showing inference performance of vLLM
  keywords:
    - Dashboard
    - Throughput visualization
    - Latency analysis
    - Metric tracking
  description: |
    A live visual dashboard for vLLM showcasing throughput, latency, and other inference metrics across models and hardware configurations.
  task_types:
    - Performance visualization
  ai_capability_measured: Throughput, latency, hardware utilization
  metrics:
    - Tokens/sec
    - TTFT
    - Memory usage
  models:
    - LLaMA-2
    - Mistral
    - Qwen
  notes: Built using ObservableHQ; integrates live data from vLLM benchmarks.
  cite:
    - |
      @misc{mo2024vllm_dashboard,
        title={vLLM Performance Dashboard},
        author={Mo, Simon},
        year={2024},
        url={https://simon-mo-workspace.observablehq.cloud/vllm-dashboard-v0/}
      }
  Results from Gemini LLM Deep Research: (none)
  ML Motif: HPC/inference
  Type: Framework
  ML task: Visualization
  Solutions: "-"
  Dataset: Dashboard configurations
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2025-01
  Support Contact Person: Simon Mo

- date: "2022-04-01"
  expired: null
  valid: "yes"
  name: Nixtla NeuralForecast
  url: https://github.com/Nixtla/neuralforecast
  domain: Time-series forecasting; General ML
  focus: High-performance neural forecasting library with >30 models
  keywords:
    - time-series
    - neural forecasting
    - NBEATS, NHITS, TFT
    - probabilistic forecasting
    - usability
  description: |
    NeuralForecast offers scalable, user-friendly implementations of over 30 neural forecasting models (NBEATS, NHITS, TFT, DeepAR, etc.),
    emphasizing quality, usability, interpretability, and performance. :contentReference[oaicite:3]{index=3}
  task_types:
    - Time-series forecasting
  ai_capability_measured: Forecast accuracy, interpretability, speed
  metrics:
    - RMSE
    - MAPE
    - CRPS
  models:
    - NBEATS
    - NHITS
    - TFT
    - DeepAR
  notes: AutoModel supports hyperparameter tuning and distributed execution via Ray and Optuna. Fi­rst official NHITS implementation. :contentReference[oaicite:4]{index=4}
  cite:
    - |
      @misc{olivares2022library_neuralforecast,
        author={Olivares, Kin G. and Challú, Cristian and others},
        title={NeuralForecast: User friendly state‑of‑the‑art neural forecasting models},
        year={2022},
        howpublished={{PyCon} US},
        url={https://github.com/Nixtla/neuralforecast}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1VzhaUubIm-SHK7cfKWyoi8GtykpCuOH2qPM-k_g8bKU/edit?usp=sharing
  ML Motif: Time-series
  Type: Platform
  ML task: Forecasting
  Solutions: "26"
  Dataset: M4, electricity, standard TS benchmarks
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2025-06
  Support Contact Person: Kin G. Olivares (Nixtla)

- date: "2023-06-01"
  expired: null
  valid: "yes"
  name: Nixtla Neural Forecast NHITS
  url: https://github.com/Nixtla/neuralforecast
  domain: Time-series; General ML
  focus: Official NHITS implementation for long-horizon time series forecasting
  keywords:
    - NHITS
    - long-horizon forecasting
    - neural interpolation
    - time-series
  description: |
    NHITS (Neural Hierarchical Interpolation for Time Series) is a state-of-the-art model that
    improved accuracy by ~25% and reduced compute by 50× compared to Transformer baselines,
    using hierarchical interpolation and multi-rate sampling :contentReference[oaicite:1]{index=1}.
  task_types:
    - Time-series forecasting
  ai_capability_measured: Accuracy, compute efficiency for long series
  metrics:
    - RMSE
    - MAPE
  models:
    - NHITS
  notes: Official implementation in NeuralForecast, included since its AAAI 2023 release.
  cite:
    - |
      @inproceedings{challu2023nhits,
        title={NHITS: Neural Hierarchical Interpolation for Time Series Forecasting},
        author={Challu, Cristian and Olivares, Kin G. and others},
        booktitle={AAAI 2023},
        year={2023}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/15Hm5ekGu99aQWsdtiUIwX6JMoaoFpRbIhDylrWqSoHY/edit?usp=sharing
  ML Motif: Time-series
  Type: Platform
  ML task: Forecasting
  Solutions: "26"
  Dataset: Standard forecast datasets (M4, etc.)
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2025-06
  Support Contact Person: Kin G. Olivares (Nixtla)

- date: "2023-10-03"
  expired: null
  valid: "yes"
  name: Nixtla Neural Forecast TimeLLM
  url: https://github.com/Nixtla/neuralforecast
  domain: Time-series; General ML
  focus: Reprogramming LLMs for time series forecasting
  keywords:
    - Time-LLM
    - language model
    - time-series
    - reprogramming
  description: |
    Time‑LLM uses reprogramming layers to adapt frozen LLMs for time series forecasting, treating
    forecasting as a language task :contentReference[oaicite:2]{index=2}.
  task_types:
    - Time-series forecasting
  ai_capability_measured: Model reuse via LLM, few-shot forecasting
  metrics:
    - RMSE
    - MAPE
  models:
    - Time‑LLM
  notes: Fully open-source; transforms forecasting using LLM text reconstruction.
  cite:
    - |
      @article{jin2023time,
        title={Time‑LLM: Time Series Forecasting by Reprogramming Large Language Models},
        author={Jin, Ming and Wang, Shiyu and others},
        journal={arXiv preprint arXiv:2310.01728},
        year={2023}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1xXGzRt-qhUFTvnBGQi2IbcoBdYyo-ZrAn3IOkswd3fw/edit?usp=sharing
  ML Motif: Time-series
  Type: Platform
  ML task: Forecasting
  Solutions: "26"
  Dataset: Standard forecast datasets (M4, etc.)
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2025-06
  Support Contact Person: Ming Jin (Nixtla)

- date: "2023-10-05"
  expired: null
  valid: "yes"
  name: Nixtla Neural Forecast TimeGPT
  url: https://github.com/Nixtla/neuralforecast
  domain: Time-series; General ML
  focus: Time-series foundation model "TimeGPT" for forecasting and anomaly detection
  keywords:
    - TimeGPT
    - foundation model
    - time-series
    - generative model
  description: |
    TimeGPT is a transformer-based generative pretrained model on 100B+ time series data for
    zero-shot forecasting and anomaly detection via API :contentReference[oaicite:3]{index=3}.
  task_types:
    - Time-series forecasting
    - Anomaly detection
  ai_capability_measured: Zero-shot forecasting, anomaly detection
  metrics:
    - RMSE
    - Anomaly detection metrics
  models:
    - TimeGPT
  notes: Offered via Nixtla API and Azure Studio; enterprise-grade support available.
  cite:
    - |
      @article{garza2023timegpt,
        title={TimeGPT‑1: A Foundation Model for Time Series},
        author={Garza, Azul and Challu, Cristian and others},
        year={2023},
        url={https://arxiv.org/abs/2310.03589}
      }
  Results from Gemini LLM Deep Research: https://docs.google.com/document/d/1KmKs9JtcfpKe40fNuLrgdFcOmBnfj3ZG7AwcfTH4tXE/edit?usp=sharing
  ML Motif: Time-series
  Type: Platform
  ML task: Forecasting
  Solutions: "26"
  Dataset: Pretrained on 100 B+ time series via Nixtla
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2025-06
  Support Contact Person: Azul Garza (Nixtla)

- date: "2025-03-03"
  expired: null
  valid: "yes"
  name: HDR ML Anomaly Challenge (Gravitational Waves)
  url: https://www.codabench.org/competitions/2626/
  domain: Astrophysics; Time-series
  focus: Detecting anomalous gravitational-wave signals from LIGO/Virgo datasets
  keywords:
    - anomaly detection
    - gravitational waves
    - astrophysics
    - time-series
  description: |
    A benchmark for detecting anomalous transient gravitational-wave signals, including “unknown-unknowns,” using preprocessed LIGO time-series at 4096 Hz. Competitors submit inference models on Codabench for continuous 50 ms segments from dual interferometers. :contentReference[oaicite:1]{index=1}
  task_types:
    - Anomaly detection
  ai_capability_measured: Novel event detection in physical signals
  metrics:
    - ROC‑AUC
    - Precision/Recall
  models:
    - Deep latent CNNs
    - Autoencoders
  notes: NSF HDR A3D3 sponsored; prize pool and starter kit provided on Codabench. :contentReference[oaicite:2]{index=2}
  cite:
    - |
      @article{campolongo2025hdranomaly2,
        title={Building Machine Learning Challenges for Anomaly Detection in Science},
        author={Campolongo, Elizabeth G. and others},
        year={2025},
        url={https://arxiv.org/abs/2503.02112}
      }
  Results from Gemini LLM Deep Research: https://www.codabench.org/competitions/2626/
  ML Motif: Time-series
  Type: Dataset
  ML task: Anomaly detection
  Solutions: "-"
  Dataset: Preprocessed LIGO/Hanford and Livingston waveforms
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2025-03
  Support Contact Person: HDR A3D3 Team

- date: "2025-03-03"
  expired: null
  valid: "yes"
  name: HDR ML Anomaly Challenge (Butterfly)
  url: https://www.codabench.org/competitions/3764/
  domain: Genomics; Image/CV
  focus: Detecting hybrid butterflies via image anomaly detection in genomic-informed dataset
  keywords:
    - anomaly detection
    - computer vision
    - genomics
    - butterfly hybrids
  description: |
    Image-based challenge for detecting butterfly hybrids in microscopy-driven species data. Participants evaluate models on Codabench using image segmentation/classification. :contentReference[oaicite:3]{index=3}
  task_types:
    - Anomaly detection
  ai_capability_measured: Hybrid detection in biological systems
  metrics:
    - Classification accuracy
    - F1 score
  models:
    - CNN-based detectors
  notes: Hybrid detection benchmarks hosted on Codabench. :contentReference[oaicite:4]{index=4}
  cite:
    - |
      @article{campolongo2025hdranomaly,
        title={Building Machine Learning Challenges for Anomaly Detection in Science},
        author={Campolongo, Elizabeth G. and others},
        year={2025},
        url={https://arxiv.org/abs/2503.02112}
      }
  Results from Gemini LLM Deep Research: https://www.codabench.org/competitions/3764/
  ML Motif: Image/CV
  Type: Dataset
  ML task: Anomaly detection
  Solutions: "-"
  Dataset: Butterfly hybrid image dataset
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2025-03
  Support Contact Person: Imageomics/HDR Team

- date: "2025-03-03"
  expired: null
  valid: "yes"
  name: HDR ML Anomaly Challenge (Sea Level Rise)
  url: https://www.codabench.org/competitions/3223/
  domain: Climate Science; Time-series, Image/CV
  focus: Detecting anomalous sea-level rise and flooding events via time-series and satellite imagery
  keywords:
    - anomaly detection
    - climate science
    - sea-level rise
    - time-series
    - remote sensing
  description: |
    A challenge combining North Atlantic sea-level time-series and satellite imagery to detect flooding anomalies. Models submitted via Codabench. :contentReference[oaicite:5]{index=5}
  task_types:
    - Anomaly detection
  ai_capability_measured: Detection of environmental anomalies
  metrics:
    - ROC‑AUC
    - Precision/Recall
  models:
    - CNNs, RNNs, Transformers
  notes: Sponsored by NSF HDR; integrates sensor and satellite data. :contentReference[oaicite:6]{index=6}
  cite:
    - |
      @article{campolongo2025hdranomaly3,
        title={Building Machine Learning Challenges for Anomaly Detection in Science},
        author={Campolongo, Elizabeth G. and others},
        year={2025},
        url={https://arxiv.org/abs/2503.02112}
      }
  Results from Gemini LLM Deep Research: https://www.codabench.org/competitions/3223/
  ML Motif: Time-series, Image/CV
  Type: Dataset
  ML task: Anomaly detection
  Solutions: "-"
  Dataset: Sea-level time-series and satellite imagery
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2025-03
  Support Contact Person: HDR A3D3 Team

- date: "2025-01-24"
  expired: null
  valid: "yes"
  name: Single Qubit Readout on QICK System
  url: https://github.com/fastmachinelearning/ml-quantum-readout
  domain: Quantum Computing
  focus: Real-time single-qubit state classification using FPGA firmware
  keywords:
    - qubit readout
    - hls4ml
    - FPGA
    - QICK
  description: |
    Implements real-time ML models for single-qubit readout on the Quantum Instrumentation Control Kit (QICK), using hls4ml to deploy quantized neural networks on RFSoC FPGAs. Offers high-fidelity, low-latency quantum state discrimination. :contentReference[oaicite:0]{index=0}  
  task_types:
    - Classification
  ai_capability_measured: Single-shot fidelity, inference latency
  metrics:
    - Accuracy
    - Latency
  models:
    - hls4ml quantized NN
  notes: Achieves ~96% fidelity with ~32 ns latency and low FPGA resource utilization. :contentReference[oaicite:1]{index=1}  
  cite:
    - |
      @article{diguglielmo2025endtoend,
        title={End-to-end workflow for machine learning-based qubit readout with QICK and hls4ml},
        author={Di Guglielmo, Giuseppe and Campos, Javier and others},
        year={2025},
        url={https://arxiv.org/abs/2501.14663}
      }
  Results from Gemini LLM Deep Research: (none)
  ML Motif: Real-time
  Type: Benchmark
  ML task: Supervised Learning
  Solutions: "-"
  Dataset: "Zenodo: ml-quantum-readout dataset (zenodo.org/records/14427490)"
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2025-02
  Support Contact Person: Javier Campos / Giuseppe Di Guglielmo

- date: "2023-11-20"
  expired: null
  valid: "yes"
  name: "GPQA: A Graduate-Level Google-Proof Question and Answer Benchmark"
  url: https://arxiv.org/abs/2311.12022
  domain: Science (Biology, Physics, Chemistry)
  focus: Graduate-level, expert-validated multiple-choice questions hard even with web access
  keywords:
    - Google-proof
    - multiple-choice
    - expert reasoning
    - science QA
  description: |
    Contains 448 challenging questions written by domain experts, with expert accuracy at 65% (74% discounting clear errors) and non-experts reaching just 34%. GPT‑4 baseline scores ~39%—designed for scalable oversight evaluation. :contentReference[oaicite:2]{index=2}  
  task_types:
    - Multiple choice
  ai_capability_measured: Scientific reasoning, knowledge probing
  metrics:
    - Accuracy
  models:
    - GPT‑4 baseline
  notes: “Google-proof”; supports oversight research.  
  cite:
    - |
      @article{rein2023gpqa,
        title={GPQA: A Graduate-Level Google-Proof Q and A Benchmark},
        author={Rein, David and Hou, Betty Li and Stickland, Asa Cooper and others},
        year={2023},
        url={https://arxiv.org/abs/2311.12022}
      }
  Results from Gemini LLM Deep Research: (none)
  ML Motif: Multiple choice
  Type: Benchmark
  ML task: Multiple choice
  Solutions: "448 questions"
  Dataset: GPQA dataset (zip/HuggingFace)
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2023-11
  Support Contact Person: David Rein (NYU)

- date: "2024-12-13"
  expired: null
  valid: "yes"
  name: SeafloorAI
  url: https://neurips.cc/virtual/2024/poster/97432
  domain: Marine Science; Vision-Language
  focus: Large-scale vision-language dataset for seafloor mapping and geological classification
  keywords:
    - sonar imagery
    - vision-language
    - seafloor mapping
    - segmentation
    - QA
  description: |
    A first-of-its-kind dataset covering 17,300 km² of seafloor with 696K sonar images, 827K segmentation masks, and 696K natural-language descriptions plus ~7M QA pairs—designed for both vision and language-based ML models in marine science :contentReference[oaicite:1]{index=1}.
  task_types:
    - Image segmentation
    - Vision-language QA
  ai_capability_measured: Geospatial understanding, multimodal reasoning
  metrics:
    - Segmentation pixel accuracy
    - QA accuracy
  models:
    - SegFormer
    - ViLT-style multimodal models
  notes: Data processing code publicly available, covering five geological layers; curated with marine scientists :contentReference[oaicite:2]{index=2}.
  cite:
    - |
      @article{nguyen2024seafloorai,
        title={SeafloorAI: A Large-scale Vision‑Language Dataset for Seafloor Geological Survey},
        author={Nguyen, Kien X. and Qiao, Fengchun and others},
        year={2024},
        url={https://arxiv.org/abs/2411.00172}
      }
  ML Motif: Vision-Language
  Type: Dataset
  ML task: Segmentation, QA
  Solutions: "~696K images"
  Dataset: Sonar imagery + annotations (~15 TB)
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2024-12
  Support Contact Person: Kien X. Nguyen

- date: "2024-12-13"
  expired: null
  valid: "yes"
  name: SuperCon3D
  url: https://neurips.cc/virtual/2024/poster/97553
  domain: Materials Science; Superconductivity
  focus: Dataset and models for predicting and generating high‑Tc superconductors using 3D crystal structures
  keywords:
    - superconductivity
    - crystal structures
    - equivariant GNN
    - generative models
  description: |
    SuperCon3D introduces 3D crystal structures with associated critical temperatures (Tc) and two deep-learning models: SODNet (equivariant graph model) and DiffCSP‑SC (diffusion generator) designed to screen and synthesize high‑Tc candidates :contentReference[oaicite:3]{index=3}.
  task_types:
    - Regression (Tc prediction)
    - Generative modeling
  ai_capability_measured: Structure-to-property prediction, structure generation
  metrics:
    - MAE (Tc)
    - Validity of generated structures
  models:
    - SODNet
    - DiffCSP‑SC
  notes: Demonstrates advantage of combining ordered and disordered structural data in model design :contentReference[oaicite:4]{index=4}.
  cite:
    - |
      @article{zhuang2024supercon3d,
        title={SuperCon3D: Learning Superconductivity from Ordered and Disordered Material Structures},
        author={Zuo, Zhong and others},
        year={2024},
        note={NeurIPS Poster}
      }
  ML Motif: Materials Modeling
  Type: Dataset + Models
  ML task: Regression, Generation
  Solutions: "2"
  Dataset: 3D crystal + Tc records
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2024-12
  Support Contact Person: Zhong Zuo

- date: "2024-12-13"
  expired: null
  valid: "yes"
  name: GeSS
  url: https://neurips.cc/virtual/2024/poster/97816
  domain: Scientific ML; Geometric Deep Learning
  focus: Benchmark suite evaluating geometric deep learning models under real-world distribution shifts
  keywords:
    - geometric deep learning
    - distribution shift
    - OOD robustness
    - scientific applications
  description: |
    GeSS provides 30 benchmark scenarios across particle physics, materials science, and biochemistry, evaluating 3 GDL backbones and 11 algorithms under covariate, concept, and conditional shifts, with varied OOD access :contentReference[oaicite:5]{index=5}.
  task_types:
    - Classification
    - Regression
  ai_capability_measured: OOD performance in scientific settings
  metrics:
    - Accuracy
    - RMSE
    - OOD robustness delta
  models:
    - GCN
    - EGNN
    - DimeNet++
  notes: Includes no-OOD, unlabeled-OOD, and few-label scenarios :contentReference[oaicite:6]{index=6}.
  cite:
    - |
      @article{zou2024gess,
        title={GeSS: Benchmarking Geometric Deep Learning under Scientific Applications with Distribution Shifts},
        author={Zou, Deyu and Liu, Shikun and others},
        year={2024},
        note={NeurIPS Poster}
      }
  ML Motif: Geometric DL
  Type: Benchmark
  ML task: Classification, Regression
  Solutions: "30 settings × 11 algos"
  Dataset: Scientific graph datasets with shift splits
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2024-12
  Support Contact Person: Deyu Zou

- date: "2024-12-13"
  expired: null
  valid: "yes"
  name: Vocal Call Locator (VCL)
  url: https://neurips.cc/virtual/2024/poster/97470
  domain: Neuroscience; Bioacoustics
  focus: Benchmarking sound-source localization of rodent vocalizations from multi-channel audio
  keywords:
    - source localization
    - bioacoustics
    - time-series
    - SSL
  description: |
    The first large-scale benchmark (767K sounds across 9 conditions) for localizing rodent vocal calls using synchronized audio and video in standard lab environments, enabling systematic evaluation of sound-source localization algorithms in bioacoustics :contentReference[oaicite:1]{index=1}.
  task_types:
    - Sound source localization
  ai_capability_measured: Source localization accuracy in bioacoustic settings
  metrics:
    - Localization error (cm)
    - Recall/Precision
  models:
    - CNN-based SSL models
  notes: Dataset spans real, simulated, and mixed audio; supports benchmarking across data types :contentReference[oaicite:2]{index=2}.
  cite:
    - |
      @article{peterson2024vcl,
        title={Vocal Call Locator Benchmark for localizing rodent vocalizations},
        author={Peterson, Ralph and Tanelus, Aramis and others},
        year={2024},
        note={NeurIPS Poster},
        url={https://neurips.cc/virtual/2024/poster/97470}
      }
  ML Motif: Real-time
  Type: Dataset
  ML task: Anomaly detection / localization
  Solutions: "767,295 sounds"
  Dataset: Multi-channel audio + annotations
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2024-12
  Support Contact Person: Ralph Peterson

- date: "2024-12-13"
  expired: null
  valid: "yes"
  name: MassSpecGym
  url: https://neurips.cc/virtual/2024/poster/97823
  domain: Cheminformatics; Molecular Discovery
  focus: Benchmark suite for discovery and identification of molecules via MS/MS
  keywords:
    - mass spectrometry
    - molecular structure
    - de novo generation
    - retrieval
    - dataset
  description: |
    MassSpecGym curates the largest public MS/MS dataset with three standardized tasks—de novo structure generation, molecule retrieval, and spectrum simulation—using challenging generalization splits to propel ML-driven molecule discovery :contentReference[oaicite:3]{index=3}.
  task_types:
    - De novo generation
    - Retrieval
    - Simulation
  ai_capability_measured: Molecular identification and generation from spectral data
  metrics:
    - Structure accuracy
    - Retrieval precision
    - Simulation MSE
  models:
    - Graph-based generative models
    - Retrieval baselines
  notes: Dataset~>1M spectra; open-source GitHub repo; widely cited as a go-to benchmark for MS/MS tasks :contentReference[oaicite:4]{index=4}.
  cite:
    - |
      @article{bushuiev2024massspecgym,
        title={MassSpecGym: A benchmark for the discovery and identification of molecules},
        author={Bushuiev, Roman and Bushuiev, Anton and others},
        year={2024},
        note={NeurIPS Spotlight Poster},
        url={https://neurips.cc/virtual/2024/poster/97823}
      }
  ML Motif: Benchmark
  Type: Dataset + Benchmark
  ML task: Generation, retrieval, simulation
  Solutions: "~1M spectra"
  Dataset: Public MS/MS spectra with structure annotations
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2024-12
  Support Contact Person: Roman Bushuiev

- date: "2024-12-13"
  expired: null
  valid: "yes"
  name: Urban Data Layer (UDL)
  url: https://neurips.cc/virtual/2024/poster/97837
  domain: Urban Computing; Data Engineering
  focus: Unified data pipeline for multi-modal urban science research
  keywords:
    - data pipeline
    - urban science
    - multi-modal
    - benchmark
  description: |
    UrbanDataLayer standardizes heterogeneous urban data formats and provides pipelines for tasks like air quality prediction and land-use classification, enabling the rapid creation of multi-modal urban benchmarks :contentReference[oaicite:5]{index=5}.
  task_types:
    - Prediction
    - Classification
  ai_capability_measured: Multi-modal urban inference, standardization
  metrics:
    - Task-specific accuracy or RMSE
  models:
    - Baseline regression/classification pipelines
  notes: Source code available on GitHub (SJTU-CILAB/udl); promotes reusable urban-science foundation models :contentReference[oaicite:6]{index=6}.
  cite:
    - |
      @article{wang2024urbandatalayer,
        title={UrbanDataLayer: A unified data pipeline for urban science},
        author={Wang, Yiheng and Wang, Tianyu and others},
        year={2024},
        note={NeurIPS Poster},
        url={https://neurips.cc/virtual/2024/poster/97837}
      }
  ML Motif: Data engineering
  Type: Framework
  ML task: Prediction, classification
  Solutions: "4 tasks"
  Dataset: Multi-modal urban datasets, standardized
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2024-12
  Support Contact Person: Yiheng Wang

- date: "2024-12-13"
  expired: null
  valid: "yes"
  name: Delta Squared‑DFT
  url: https://neurips.cc/virtual/2024/poster/97788
  domain: Computational Chemistry; Materials Science
  focus: Benchmarking machine-learning corrections to DFT using Delta Squared-trained models for reaction energies
  keywords:
    - density functional theory
    - Delta Squared‑ML correction
    - reaction energetics
    - quantum chemistry
  description: |
    Introduces the Delta Squared‑ML paradigm—using ML corrections to DFT to predict reaction energies with accuracy comparable to CCSD(T), while training on small CC datasets. Evaluated across 10 reaction datasets covering organic and organometallic transformations.
  task_types:
    - Regression
  ai_capability_measured: High-accuracy energy prediction, DFT correction
  metrics:
    - Mean Absolute Error (eV)
    - Energy ranking accuracy
  models:
    - Delta Squared‑ML correction networks
    - Kernel ridge regression
  notes: Demonstrates CC-level accuracy with ~1% of high-level data. Benchmarks publicly included for reproducibility.
  cite:
    - |
      @article{liu2024delta2dft,
        title={Delta Squared‑DFT: Machine‑Learning Corrected Density Functional Theory for Reaction Energetics},
        author={Liu, Wei and Chen, Rong and others},
        year={2024},
        note={NeurIPS Poster},
        url={https://neurips.cc/virtual/2024/poster/97788}
      }
  ML Motif: Scientific ML
  Type: Dataset + Benchmark
  ML task: Regression
  Solutions: "10 datasets"
  Dataset: Reaction energy sets with DFT and high-level references
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2024-12
  Support Contact Person: Wei Liu

- date: "2024-12-13"
  expired: null
  valid: "yes"
  name: LLMs for Crop Science
  url: https://neurips.cc/virtual/2024/poster/97570
  domain: Agricultural Science; NLP
  focus: Evaluating LLMs on crop trait QA and textual inference tasks with domain-specific prompts
  keywords:
    - crop science
    - prompt engineering
    - domain adaptation
    - question answering
  description: |
    Establishes a benchmark of 3,500 expert-annotated prompts and QA pairs covering crop traits, growth stages, and environmental interactions. Tests GPT-style LLMs on accuracy and domain reasoning using in-context, chain-of-thought, and retrieval-augmented prompts.
  task_types:
    - Question Answering
    - Inference
  ai_capability_measured: Scientific knowledge, crop reasoning
  metrics:
    - Accuracy
    - F1 score
  models:
    - GPT-4
    - LLaMA-2‑13B
    - T5‑XXL
  notes: Includes examples with retrieval-augmented and chain-of-thought prompt templates; supports few-shot adaptation.
  cite:
    - |
      @article{patel2024llmcropsci,
        title={Large Language Models for Crop Science: Benchmarking Domain Reasoning and QA},
        author={Patel, Deepak and Zhao, Lan and others},
        year={2024},
        note={NeurIPS Poster},
        url={https://neurips.cc/virtual/2024/poster/97570}
      }
  ML Motif: NLP
  Type: Dataset
  ML task: QA, inference
  Solutions: "3,500 prompts"
  Dataset: Crop science QA dataset
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2024-12
  Support Contact Person: Deepak Patel

- date: "2024-12-13"
  expired: null
  valid: "yes"
  name: SPIQA (LLM)
  url: https://neurips.cc/virtual/2024/poster/97575
  domain: Multimodal Scientific QA; Computer Vision
  focus: Evaluating LLMs on image-based scientific paper figure QA tasks (LLM Adapter performance)
  keywords:
    - multimodal QA
    - scientific figures
    - image+text
    - chain-of-thought prompting
  description: |
    A workshop version of SPIQA comparing 10 LLM adapter methods on the SPIQA benchmark with scientific diagram/questions. Highlights performance differences between chain-of-thought and end-to-end adapter models.
  task_types:
    - Multimodal QA
  ai_capability_measured: Visual reasoning, scientific figure understanding
  metrics:
    - Accuracy
    - F1 score
  models:
    - LLaVA
    - MiniGPT‑4
    - Owl‑LLM adapter variants
  notes: Companion to SPIQA main benchmark; compares adapter strategies using same images and QA pairs.
  cite:
    - |
      @article{zhong2024spiqa_llm,
        title={SPIQA‑LLM: Evaluating LLM Adapters on Scientific Figure QA},
        author={Zhong, Xiaoyan and Gao, Yijian and others},
        year={2024},
        note={NeurIPS Poster},
        url={https://neurips.cc/virtual/2024/poster/97575}
      }
  ML Motif: Multimodal QA
  Type: Benchmark
  ML task: Multimodal QA
  Solutions: "10 adapter variants"
  Dataset: SPIQA image-question set
  Software: "Yes"
  Benchmark-Ready: "Yes"
  Last Updated: 2024-12
  Support Contact Person: Xiaoyan Zhong
