# AIME (American Invitational Mathematics Examination)

<p><a class="md-button back-link" href="../">‚Üê Back to all benchmarks</a></p>
<div class="info-block meta-block">
  <p class="meta-row"><span class="meta-label">Date</span><span class="meta-sep">:</span> <span class="meta-value">2025-03-13</span></p>
  <p class="meta-row"><span class="meta-label">Name</span><span class="meta-sep">:</span> <span class="meta-value">AIME  American Invitational Mathematics Examination</span></p>
  <p class="meta-row"><span class="meta-label">Domain</span><span class="meta-sep">:</span> <span class="meta-value">Mathematics</span></p>
  <p class="meta-row"><span class="meta-label">Focus</span><span class="meta-sep">:</span> <span class="meta-value">Pre-college advanced problem solving</span></p>
  <p class="meta-row"><span class="meta-label">Task Types</span><span class="meta-sep">:</span> <span class="meta-value">Problem solving</span></p>
  <p class="meta-row"><span class="meta-label">Metrics</span><span class="meta-sep">:</span> <span class="meta-value">Accuracy</span></p>
  <p class="meta-row"><span class="meta-label">Models</span><span class="meta-sep">:</span> <span class="meta-value">unkown</span></p>
</div>
<h3>Keywords</h3>

<div class="chips"><a class="chip chip-link" href="../#kw=algebra">algebra</a> <a class="chip chip-link" href="../#kw=combinatorics">combinatorics</a> <a class="chip chip-link" href="../#kw=number%20theory">number theory</a> <a class="chip chip-link" href="../#kw=geometry">geometry</a> </div>
<h3>Citation</h3>

- TBD. Aime. March 2025. [Online accessed 2025-06-24]. URL: https://www.vals.ai/benchmarks/aime-2025-03-13.

<pre><code class="language-bibtex">@misc{www-aime,
  author = {TBD},
  title = {AIME},
  url = {https://www.vals.ai/benchmarks/aime-2025-03-13},
  month = mar,
  year = 2025,
  note = {[Online accessed 2025-06-24]}
}</code></pre>
<h3>Ratings</h3>
<div class="ratings-grid">
  <div class="ratings-head ratings-cell"><span>Category</span><span>Rating</span></div>
  <div class="rating-item">  <div class="rating-cat">Software</div>  <div class="rating-badge">0.00</div>  <div class="rating-bar"><span style="width:0%"></span></div>  <div class="rating-reason">No code available
</div></div><div class="rating-item">  <div class="rating-cat">Specification</div>  <div class="rating-badge">0.00</div>  <div class="rating-bar"><span style="width:0%"></span></div>  <div class="rating-reason">Obvious what the problems are, but not specified how to administer them to AI models. No HW constraints
</div></div><div class="rating-item">  <div class="rating-cat">Dataset</div>  <div class="rating-badge">4.00</div>  <div class="rating-bar"><span style="width:80%"></span></div>  <div class="rating-reason">Easily accessible data with problems and solutions, but no splits
</div></div><div class="rating-item">  <div class="rating-cat">Metrics</div>  <div class="rating-badge">5.00</div>  <div class="rating-bar"><span style="width:100%"></span></div>  <div class="rating-reason">(by default) Answer is correct or it&#x27;s not
</div></div><div class="rating-item">  <div class="rating-cat">Reference Solution</div>  <div class="rating-badge">0.00</div>  <div class="rating-bar"><span style="width:0%"></span></div>  <div class="rating-reason">Not given. Human performance stats exist, but no mentions of AI performance
</div></div><div class="rating-item">  <div class="rating-cat">Documentation</div>  <div class="rating-badge">0.00</div>  <div class="rating-bar"><span style="width:0%"></span></div>  <div class="rating-reason">Not given
</div></div>
</div>
<div class="avg-rating">  <strong>Average rating:</strong> <span class="badge badge--bad badge--sm">1.50/5</span></div><h3>Radar plot</h3>

<div class="radar-wrap"><img class="radar-img" alt="AIME (American Invitational Mathematics Examination) radar" src="../../../tex/images/aime_american_invitational_mathematics_examination_radar.png" /></div>

<p><strong>Edit:</strong> <a href="https://github.com/mlcommons-science/benchmark/tree/main/source">edit this entry</a></p>
