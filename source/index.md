# MLCommons Science Working Group AI Benchmarks Collection

This site curates a collection of AI benchmarks.  
The main artifact is the PDF report:

- **Report (PDF):** [benchmarks.pdf](benchmarks.pdf)

If you cite this work, please reference the PDF (not the Markdown pages). A BibTeX entry is provided below.

```bibtex
@misc{benchmark-collection,
  title        = {MLCommons Science Working Group AI Benchmarks Collection},
  author       = {Gregor von Laszewski and
                  Reece Shiraishi and
                  Anjay Krishnan and
                  Nhan Tran and
                  Benjamin Hawks and
                  Marco Colombo and
                  Geoffrey C. Fox},
  year         = {2025},
  month        = jul,
  howpublished = {GitHub},
  url          = {https://mlcommons-science.github.io/benchmark/benchmarks.pdf}
}
```

For online browsing, we provide two views:

- **[Benchmarks (cards)](md/benchmarks/)**: filterable and sortable index with detail pages.
- **[Benchmarks (table)](md/benchmarks_table.md)**: compact Markdown table with links to the same detail pages.

> **Note:** The Markdown pages are generated for web browsing and should **not** be cited. Please cite the PDF report above.

All pages are generated automatically, please donâ€™t edit them directly.  
To propose changes, update the source files here:

- <https://github.com/mlcommons-science/benchmark/tree/main/source>

For program improvements, please contact **Gregor von Laszewski** at `laszewski at gmail.com`.

The project README is available at:

- <https://github.com/mlcommons-science/benchmark>
