\subsection{SciCode}
{{\footnotesize
\noindent SciCode is a scientist-curated coding benchmark with 338 subproblems derived from 80
real research tasks across 16 scientific subfields, evaluating models on knowledge recall, 
reasoning, and code synthesis for scientific computing tasks.


\begin{description}[labelwidth=4cm, labelsep=1em, leftmargin=4cm, itemsep=0.1em, parsep=0em]
  \item[date:] 2024-07-18
  \item[version:] 1
  \item[last\_updated:] 2024-07-18
  \item[expired:] false
  \item[valid:] yes
  \item[valid\_date:] 2024-07-18
  \item[url:] \href{https://scicode-bench.github.io/}{https://scicode-bench.github.io/}
  \item[doi:] 10.48550/arXiv.2407.13168
  \item[domain:]
    - Computational Science \& AI
  \item[focus:] Scientific code generation and problem solving
  \item[keywords:]
    - code synthesis
    - scientific computing
    - programming benchmark
  \item[licensing:] unknown
  \item[task\_types:]
    - Coding
  \item[ai\_capability\_measured:]
    - Program synthesis, scientific computing
  \item[metrics:]
    - Solve rate (\%)
  \item[models:]
    - Claude3.5-Sonnet
  \item[ml\_motif:]
    - Generative
  \item[type:] Benchmark
  \item[ml\_task:]
    - Supervised Learning
  \item[solutions:] unknown
  \item[notes:] Good
  \item[contact.name:] Minyang Tian
  \item[contact.email:] mtian8@illinois.edu
  \item[datasets.links.name:] SciCode on Huggingface
  \item[datasets.links.url:] \href{https://huggingface.co/datasets/SciCode1/SciCode}{https://huggingface.co/datasets/SciCode1/SciCode}
  \item[results.links.name:] SciCode Learderboard
  \item[results.links.url:] \href{https://scicode-bench.github.io/leaderboard/}{https://scicode-bench.github.io/leaderboard/}
  \item[fair.reproducible:] Yes
  \item[fair.benchmark\_ready:] Yes
  \item[id:] scicode
  \item[Citations:] \cite{tian2024scicoderesearchcodingbenchmark}
\end{description}

{\bf Ratings:} ~ \\

\begin{tabular}{p{0.15\textwidth} p{0.07\textwidth} p{0.7\textwidth}}
\hline
Rating & Value & Reason \\
\hline
dataset & 5 & Dataset meets all FAIR principles, test and validation splits are available (no train split)
 \\
documentation & 4 & Paper containing all needed info except for evlauation criteria
 \\
metrics & 4 & Metrics stated, grading guidelines are provided in repo (problems are pass/fail)
 \\
reference\_solution & 5 & Code to evaluate is available and well documented. Baseline models include closed and open weight models
 \\
software & 5 & Code to run exists on github repo
 \\
specification & 4 & Expected outputs and broad types of inputs stated. Few details on output grading. No HW constraints.
 \\
\hline
\end{tabular}

\includegraphics[width=0.2\textwidth]{scicode_radar.pdf}
}}
\clearpage