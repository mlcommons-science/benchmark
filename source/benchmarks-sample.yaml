- date: '2024-05-01'
  last_updated: '2024-05-01'
  expired:
  valid: 'yes' #CHECK DEFINITION
  name: Jet Classification
  url: 
    https://github.com/fastmachinelearning/fastml-science/tree/main/jet-classify
  domain:
  - Particle Physics
  focus: Real-time classification of particle jets using HL-LHC simulation 
    features                                                                                                                                               #Perhaps put under "focus"
  keywords:
  - classification
  - real-time ML
  - jet tagging
  - QKeras
  description: |
    This benchmark evaluates ML models for real-time classification of
    particle jets using high-level features derived from simulated LHC data. It
    includes both full-precision and quantized models optimized for FPGA deployment.
  task_types:
  - Classification
  ai_capability_measured:
  - Real-time inference
  - Model compression performance
  metrics:
  - Accuracy
  - AUC
  models:
  - Keras DNN
  - QKeras quantized DNN
  ml_motif:
  - Real-time
  type: Benchmark
  ml_task: Supervised Learning
  solutions: '2' #NOT NEEDED. Number of results as a list
  notes: Includes both float and quantized models using QKeras
  contact:
    name: Jules Muhizi
    email:
  cite:
  - |
    @article{hawks2022fastml,
      title={Fast Machine Learning for Science: Benchmarks and Dataset},
      author={Hawks, Ben and Tran, Nhan and others},
      year={2022},
      url={https://arxiv.org/abs/2207.07958}
    }
  dataset:
  - name: OpenML
    url: hls4ml_lhc_jets_hlf (https://www.openml.org/d/42468)
  - name: JetClass
    url: https://zenodo.org/record/6619768
  results:
  - name: Gemini LLM Deep Research
    url: 
      https://docs.google.com/document/d/1Mr7J4F8PDAIBXJ2vrfVssxLekEVW7ahJ4wpSe6FN5yw
  - name: ChatGPT LLM
    url: 
      https://docs.google.com/document/d/1runrcij-eoH3_lgGZ8wm2z1YbL1Qf5cSNbVbHyWFDs4
  fair:
    reproducible: true
    benchmark_ready: true #"Is it runnable?"
  ratings:
    software:
      rating: 0
      reason: could not set up the software environment
    specification:
      rating: 5.0
      reason: |
        Task and format (multiple-choice QA with 5 options) are clearly
        defined; grounded in ConceptNet with consistent structure, though no hardware/system
        constraints are specified.
    dataset:
      rating: 5.0
      reason: |
        Public, versioned, and FAIR-compliant; includes metadata, splits,
        and licensing; well-integrated with HuggingFace and other ML libraries.
    metrics:
      rating: 5.0
      reason: |
        Accuracy is a simple, reproducible metric aligned
        with task goals; no ambiguity in evaluation.
    reference_solution:
      rating: 4.0
      reason: |
        Several baseline models (e.g., BERT, RoBERTa) are reported
        with scores; implementations exist in public repos, but not bundled as an official
        starter kit.
    documentation:
      rating: 3.0
      reason: |
        Clear paper, GitHub repo, and integration with HuggingFace
        Datasets; full reproducibility requires manually connecting models to dataset.
